{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from main import initiate_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Collect data distribution\n",
    "fname = \"../data/Bret_cover_ramets.csv\"\n",
    "df = pd.read_csv(fname,delimiter=',', decimal=',')\n",
    "\n",
    "# Collect data diameter\n",
    "fname = \"../data/Bret_cover_ramets2.csv\"\n",
    "df2 = pd.read_csv(fname,delimiter=',', decimal='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to combine the data from diameter and seperate ramets on larger distance. Let's say the area within the diameter circle is 50% filled, and equally distributed. The amount of cloned individuals in this area is $N =\\frac{\\pi D^2}{8} - 9$, so the amount of individuals I'm expecting at distance $r$ is $\\frac{N}{r} = \\frac{2}{D}(\\frac{\\pi D^2}{8} - 9)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 61.    50.    51.    54.   114.    89.    88.    80.    50.    48.\n",
      "  41.    27.    34.    66.    77.    93.    98.    37.    54.   103.\n",
      "  45.    47.   110.    80.    52.    70.    44.    32.    51.    62.\n",
      "  31.5   44.1   44.    52.5  120.    67.    63.    40.    33.    40.\n",
      "  34.4   33.82  82.49  62.57  33.    27.39  43.68  68.    40.45  50.53\n",
      "  40.6   36.   100.    80.    72.    27.54  24.2   61.    57.    20.\n",
      "  36.    23.    50.    70.    40.    32.   112.    57.    88.    86.17\n",
      "  30.   170.    56.2   84.16  22.   120.    80.    90.    32.52 101.25\n",
      "  40.    30.    80.    42.    53.58  35.22  63.2   46.99  42.58 100.\n",
      " 110.    80.    75.74 100.    45.    30.    40.    40.    40.    56.\n",
      "  81.4   50.    60.    64.    60.    36.53  56.23  36.19  46.    63.\n",
      "  40.    36.    57.79  29.42  20.86  41.46  37.59  42.09  96.51  62.\n",
      "  42.    80.    50.    42.    65.    42.    39.    35.   140.    90.\n",
      " 110.   110.   110.    80.   150.    90.    60.   140.   130.    50.\n",
      " 120.    70.    40.   170.    80.    40.    33.    50.    90.    70.\n",
      " 100.    40.    75.    40.    17.    57.    50.    80.    50.    56.\n",
      "  63.    54.    54.   100.    27.    77.    50.    23.    92.    28.\n",
      " 110.   100.    60.    80.    40.    52.    48.    42.   100.    51.\n",
      "  62.  ]\n",
      "[nan nan  4.  8.  1.  1. nan  1. nan nan nan  1.  1.  2.  1.  2.  5. nan\n",
      "  1.  1.  3.  2.  1. nan nan nan  1.  1.  5. nan  1.  6. nan  1.  2.  1.\n",
      "  1.  1. nan nan  1.  2. nan  1.  1.  4.  1.  1. nan  2.  1.  1.  4.  5.\n",
      "  1.  3.  1.  3.  1.  1.  2.  1.  1. nan nan nan nan nan nan nan  3.  1.\n",
      " nan nan  1. nan nan nan  1.  3.  1.  1. nan nan  1. nan  1.  1.  2.  1.\n",
      " nan nan nan nan  1.  1.  1.  1.  2.  1.  2.  2. nan nan  2. nan nan  1.\n",
      "  4.  1.  1.  3.  1.  3.  2.  1.  5.  3. nan nan  1. nan  1.  1. nan  1.\n",
      " nan  1.  1.  1.  1.  1. nan  3.  1.  9. nan  1.  2.  1.  1. nan  1. nan\n",
      "  1.  2. nan nan nan nan  1.  1.  1.  2.  1.  1. nan nan nan nan nan nan\n",
      "  2.  3. nan  4. nan  1.  1.  1.  1. nan  1.  2.  1.  1.  1. nan nan nan\n",
      " nan  1. nan nan  1.  1. nan nan nan nan  3.  5.  3.  1.  1.  1.  3.  1.\n",
      "  2. nan nan nan  1. nan nan nan nan nan  1. nan  1.  1. nan nan  1.  1.\n",
      "  1.  3. nan  3.  2.  1.  1.  2.  2.  1.  1.  1. nan nan  1. nan nan  1.\n",
      "  1.  1.  3.  1. nan nan nan nan  2. nan nan nan  1.  1.  1.  1.  2.  1.\n",
      "  1.  1.]\n",
      "Mean: 6.701, Std: 6.756\n"
     ]
    }
   ],
   "source": [
    "fill = 0.5\n",
    "\n",
    "# Get mean and std deviation of clones\n",
    "d_close = df2.ix[:, ['D_3']].values[:,0]\n",
    "dN_dr = 2/d_close * ((np.pi*d_close**2 / 8) - 9)\n",
    "print(d_close)\n",
    "d = df.ix[:, ['NR_3', 'NR_3_distance(cm)']].values\n",
    "print(d[:,0])\n",
    "weights, mids = d.T\n",
    "mean = np.average(mids[~np.isnan(mids)], weights=weights[~np.isnan(weights)])\n",
    "std = np.average((mids[~np.isnan(mids)] - mean)**2, weights=weights[~np.isnan(weights)])\n",
    "print(\"Mean: %.3f, Std: %.3f\"%(mean, std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Collect modelled patches and corresponding data\n",
    "models = initiate_models(data.get_params()[0])\n",
    "data.assign_data(models)\n",
    "patches = []\n",
    "for model in models:\n",
    "    patches += model.patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n"
     ]
    }
   ],
   "source": [
    "labels_data = df.ix[:, ['plot', 'patch']].values\n",
    "labels = [\"%02d%s%s\" % (plot, patch[1:], patch[0]) for plot, patch in labels_data]\n",
    "counts = []\n",
    "for count, label in zip(weights, labels):\n",
    "    if not np.isnan(count):\n",
    "        for patch in patches:\n",
    "            if patch.id.strip(\"*\") == label and patch.has_data:\n",
    "                nr = patch.factor * 9\n",
    "                biom_0 = patch.BR_data[0]\n",
    "                biom_T = patch.BR_data[2]\n",
    "                counts.append((biom_0/nr, biom_T/nr, count/nr))\n",
    "                break\n",
    "        else:\n",
    "            raise FileNotFoundError(label)\n",
    "\n",
    "print(len(counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We collected the summed probability over the whole period until measurement 3. We now want this final amount of seeds per biomass to the seed probability $p_{seed}$ on every timestep. \n",
    "\n",
    "$$ N_{seeds}\\big |_{t=T} = \\sum_{t=0}^Tp_{seeds}B_t$$\n",
    "\n",
    "$$= p_{seeds}B_0\\sum_{t=0}^Tr^t$$\n",
    "\n",
    "$$= p_{seeds}B_0\\frac{1 - r^{T+1}}{1 - r}$$\n",
    "\n",
    "$$ p_{seed} = \\frac{N_{seeds}}{B_0}\\frac{1 - r}{1 - r^{T+1}}$$\n",
    "\n",
    "Where we can approximate $r$ by\n",
    "\n",
    "$$B_T = B_0r^T$$\n",
    "$$r = \\left(\\frac{B_T}{B_0}\\right)^{\\frac{1}{T}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n",
      "1.6145152003684937\n",
      "Average r = 1.0040678677\n"
     ]
    }
   ],
   "source": [
    "T = (data.end_date - data.start_date).days\n",
    "B_T_B_0 = np.mean([b[1]/b[0] for b in counts])\n",
    "r_average = B_T_B_0**(1/T)\n",
    "\n",
    "print(T)\n",
    "print(B_T_B_0)\n",
    "print('Average r = %.10f'%r_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0030063076304832023 0.0029281088743420293\n"
     ]
    }
   ],
   "source": [
    "p_seeds = []\n",
    "N_total = 0\n",
    "for B_0, B_T, n_total in counts:\n",
    "    r = (B_T/B_0)**(1/T)\n",
    "    p = n_total/B_0*(1 - r)/(1 - r**(T+1))\n",
    "    N_total += n_total\n",
    "    p_seeds.append(p)\n",
    "    \n",
    "print(np.mean(p_seeds), np.std(p_seeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed_prob = 0.003 +/- 0.003\n",
      "seed_mean = 6.701\n",
      "seed_sigma = 6.756\n"
     ]
    }
   ],
   "source": [
    "print(\"seed_prob = %.3f +/- %.3f\"%(np.mean(p_seeds), np.std(p_seeds)))\n",
    "print(\"seed_mean = %.3f\"%mean)\n",
    "print(\"seed_sigma = %.3f\"%std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But now I calculated the expansion over only the counted ramnus clones. These are a tiny fraction of the total expansion of the patch. It makes more sense to look at the expansion of the patch in diameter to estimate $N_{total}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.850120899171271 3.2650349587793652\n",
      "6.232845303867404 2.971909970220621\n"
     ]
    }
   ],
   "source": [
    "# Get mean and std deviation of clones\n",
    "d = df2.ix[:, ['D_1', 'D_3']].values\n",
    "D_0, D_T = d.T\n",
    "S_0, S_T = (.1*D_0)**2, np.pi*(.05*D_T)**2\n",
    "print(np.mean(S_0), np.std(S_0))\n",
    "print(np.mean(.1*D_T), np.std(.1*D_T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I square the diameter I get a mean of 5 square cm's. In the model I initiate with 9 square cm's. Should I follow that? It makes a big difference for the growth factor!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0804590607826439 2.1068087880222417\n"
     ]
    }
   ],
   "source": [
    "# Now lets say that we start with out 9x9 square and that the expansion is maximally 50% covered\n",
    "N_total = (fill*S_T - 9)/9\n",
    "print(np.mean(N_total), np.std(N_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03294610506340718 0.06457455047638556\n"
     ]
    }
   ],
   "source": [
    "p_seeds = []\n",
    "for B_0, B_T, _ in counts:\n",
    "    r = (B_T/B_0)**(1/T)\n",
    "    p = N_total/B_0*(1 - r)/(1 - r**(T+1))\n",
    "    p_seeds.append(p)\n",
    "    \n",
    "print(np.mean(p_seeds), np.std(p_seeds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the number I found, around 3%, to be reasonable for a nice visual result... Is 35% cover for the patch maybe a big on the low side though?... In the calculation I didn't take the biomass of the new ramets into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
